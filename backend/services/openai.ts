// ğŸ“ backend/services/openai.ts
// OpenAI API í˜¸ì¶œ ì„œë¹„ìŠ¤

import { logger } from '../utils/logger';
import { getFromCache, setToCache } from '../utils/cache';

// ë©”ì‹œì§€ íƒ€ì… ì •ì˜
type Message = {
  role: string;
  content: string;
}

/**
 * OpenAI GPT-3.5 ëª¨ë¸ í˜¸ì¶œ
 * @param messages ë©”ì‹œì§€ ë°°ì—´
 * @returns ìƒì„±ëœ í…ìŠ¤íŠ¸
 */
export async function callGPT35(messages: Message[]): Promise<string> {
  logger.info('GPT-3.5 ëª¨ë¸ í˜¸ì¶œ ì‹œì‘');
  
  try {
    // ìºì‹±ì„ ìœ„í•œ í‚¤ ìƒì„±
    const cacheKey = generateCacheKey(messages, 'gpt-3.5-turbo');
    const cachedResponse = await getFromCache(cacheKey);
    
    if (cachedResponse) {
      logger.info('GPT-3.5 ìºì‹œëœ ì‘ë‹µ ì‚¬ìš©');
      return cachedResponse;
    }
    
    // OpenAI API í‚¤ í™•ì¸
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      logger.error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      throw new Error('API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }
    
    // API ìš”ì²­ ì˜µì…˜
    const apiUrl = 'https://api.openai.com/v1/chat/completions';
    const requestBody = {
      model: 'gpt-3.5-turbo',
      messages: messages,
      temperature: 0.7,
      max_tokens: 1000
    };
    
    // fetch APIë¡œ ì§ì ‘ í˜¸ì¶œ
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(requestBody)
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      logger.error(`GPT-3.5 API ì˜¤ë¥˜: ${response.status} ${errorText}`);
      throw new Error(`API ì˜¤ë¥˜: ${response.status} ${errorText}`);
    }
    
    const result = await response.json();
    const responseText = result.choices[0]?.message?.content || '';
    
    // ì‘ë‹µ ìºì‹± (1ì‹œê°„)
    await setToCache(cacheKey, responseText, 60 * 60);
    
    return responseText;
  } catch (error) {
    logger.error('GPT-3.5 API í˜¸ì¶œ ì˜¤ë¥˜:', error);
    throw error;
  }
}

/**
 * OpenAI GPT-4 ëª¨ë¸ í˜¸ì¶œ
 * @param messages ë©”ì‹œì§€ ë°°ì—´
 * @returns ìƒì„±ëœ í…ìŠ¤íŠ¸
 */
export async function callGPT4(messages: Message[]): Promise<string> {
  logger.info('GPT-4 ëª¨ë¸ í˜¸ì¶œ ì‹œì‘');
  
  try {
    // ìºì‹±ì„ ìœ„í•œ í‚¤ ìƒì„±
    const cacheKey = generateCacheKey(messages, 'gpt-4');
    const cachedResponse = await getFromCache(cacheKey);
    
    if (cachedResponse) {
      logger.info('GPT-4 ìºì‹œëœ ì‘ë‹µ ì‚¬ìš©');
      return cachedResponse;
    }
    
    // OpenAI API í‚¤ í™•ì¸
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      logger.error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      throw new Error('API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }
    
    // API ìš”ì²­ ì˜µì…˜
    const apiUrl = 'https://api.openai.com/v1/chat/completions';
    const requestBody = {
      model: 'gpt-4',
      messages: messages,
      temperature: 0.7,
      max_tokens: 1000
    };
    
    // fetch APIë¡œ ì§ì ‘ í˜¸ì¶œ
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(requestBody)
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      logger.error(`GPT-4 API ì˜¤ë¥˜: ${response.status} ${errorText}`);
      throw new Error(`API ì˜¤ë¥˜: ${response.status} ${errorText}`);
    }
    
    const result = await response.json();
    const responseText = result.choices[0]?.message?.content || '';
    
    // ì‘ë‹µ ìºì‹± (1ì‹œê°„)
    await setToCache(cacheKey, responseText, 60 * 60);
    
    return responseText;
  } catch (error) {
    logger.error('GPT-4 API í˜¸ì¶œ ì˜¤ë¥˜:', error);
    throw error;
  }
}

/**
 * ë©”ì‹œì§€ì™€ ëª¨ë¸ì— ê¸°ë°˜í•œ ìºì‹œ í‚¤ ìƒì„±
 * @param messages ë©”ì‹œì§€ ë°°ì—´
 * @param model ëª¨ë¸ëª…
 * @returns ìºì‹œ í‚¤
 */
function generateCacheKey(messages: Message[], model: string): string {
  const messageKey = messages.map(msg => `${msg.role}:${msg.content.substring(0, 50)}`).join('|');
  // MD5 í•´ì‹œ ë“±ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ, ê°„ë‹¨íˆ ì²˜ë¦¬
  return `openai:${model}:${messageKey.substring(0, 100)}`;
}