// ğŸ“ backend/services/openai.ts
// Create at 2504201655 Ver1.2

import OpenAI from 'openai';
import dotenv from 'dotenv';
import { logger } from '../utils/logger.js';

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.config();

console.log('ğŸ” OpenAI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...');
console.log(`ğŸ“Œ API í‚¤ ì„¤ì • í™•ì¸: ${process.env.OPENAI_API_KEY ? 'ì¡´ì¬í•¨' : 'ì—†ìŒ'}`);
if (process.env.OPENAI_API_KEY) {
  console.log(`ğŸ“Œ API í‚¤ í˜•ì‹: ${process.env.OPENAI_API_KEY.substring(0, 10)}... (${process.env.OPENAI_API_KEY.length}ì)`);
  console.log(`ğŸ“Œ Project í‚¤ ì—¬ë¶€: ${process.env.OPENAI_API_KEY.startsWith('sk-proj-')}`);
}

let openai: OpenAI;

try {
  // OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
  openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });
  console.log('âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ');
} catch (error) {
  console.error('âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
  logger.error(`OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: ${error.message}`);
  throw new Error(`OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: ${error.message}`);
}

/**
 * GPT-3.5 í˜¸ì¶œ í•¨ìˆ˜ - ë©”ì‹œì§€ ë°°ì—´ ê¸°ë°˜
 * @param messages ë©”ì‹œì§€ ë°°ì—´
 * @param options ì¶”ê°€ ì˜µì…˜
 * @returns ìƒì„±ëœ í…ìŠ¤íŠ¸
 */
export async function callGPT35(messages: Array<{role: string, content: string}>, options: any = {}) {
  try {
    logger.info(`GPT-3.5 API í˜¸ì¶œ: ë©”ì‹œì§€ ìˆ˜=${messages.length}`);
    console.log('ğŸ“ GPT-3.5 í˜¸ì¶œ ë©”ì‹œì§€:', JSON.stringify(messages).substring(0, 500));
    console.log('ğŸ“ GPT-3.5 í˜¸ì¶œ ì˜µì…˜:', JSON.stringify(options));
    
    const startTime = Date.now();
    
    // OpenAI ìš”ì²­ êµ¬ì„±
    const requestOptions = {
      model: options.model || 'gpt-3.5-turbo',
      messages: messages,
      temperature: options.temperature || 0.7,
      max_tokens: options.max_tokens || 1000,
    };
    
    console.log('ğŸ“¤ OpenAI ìš”ì²­ ì˜µì…˜:', JSON.stringify(requestOptions));
    
    // OpenAI SDKë¥¼ í†µí•œ API í˜¸ì¶œ
    try {
      const response = await openai.chat.completions.create(requestOptions);
      
      const duration = Date.now() - startTime;
      logger.info(`GPT-3.5 API ì‘ë‹µ ì™„ë£Œ: ${duration}ms, í† í°=${response.usage?.total_tokens || 'N/A'}`);
      
      console.log('ğŸ“¥ OpenAI ì‘ë‹µ:', {
        id: response.id,
        model: response.model,
        usage: response.usage,
        choices_length: response.choices.length,
        content_preview: response.choices[0]?.message?.content?.substring(0, 100)
      });
      
      // ì‘ë‹µ ê²€ì¦
      if (!response.choices || response.choices.length === 0) {
        throw new Error('OpenAI API ì‘ë‹µì— choices í•„ë“œê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
      }
      
      if (!response.choices[0].message || !response.choices[0].message.content) {
        throw new Error('OpenAI API ì‘ë‹µì˜ content í•„ë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
      }
      
      return response.choices[0].message.content;
    } catch (apiError) {
      console.error('âŒ OpenAI API ì§ì ‘ í˜¸ì¶œ ì˜¤ë¥˜:', apiError);
      
      // ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë¡œê¹…
      if (apiError.response) {
        console.error('ğŸ“Œ API ì˜¤ë¥˜ ì‘ë‹µ:', apiError.response.data);
      }
      
      // API í‚¤ ì˜¤ë¥˜ íŠ¹ë³„ ì²˜ë¦¬
      if (apiError.message.includes('API key')) {
        logger.error(`API í‚¤ ì¸ì¦ ì˜¤ë¥˜: ${apiError.message}`);
        throw new Error(`OpenAI API í‚¤ ì¸ì¦ ì˜¤ë¥˜: ${apiError.message}. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.`);
      }
      
      // ì¼ë°˜ API ì˜¤ë¥˜
      throw apiError;
    }
  } catch (error) {
    logger.error(`GPT-3.5 API ì˜¤ë¥˜: ${error.message}`);
    console.error('âŒ GPT-3.5 í˜¸ì¶œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);
    throw new Error(`GPT-3.5 í˜¸ì¶œ ì˜¤ë¥˜: ${error.message}`);
  }
}

/**
 * GPT-4 í˜¸ì¶œ í•¨ìˆ˜ - ë©”ì‹œì§€ ë°°ì—´ ê¸°ë°˜
 * @param messages ë©”ì‹œì§€ ë°°ì—´
 * @param options ì¶”ê°€ ì˜µì…˜
 * @returns ìƒì„±ëœ í…ìŠ¤íŠ¸
 */
export async function callGPT4(messages: Array<{role: string, content: string}>, options: any = {}) {
  try {
    logger.info(`GPT-4 API í˜¸ì¶œ: ë©”ì‹œì§€ ìˆ˜=${messages.length}`);
    
    const startTime = Date.now();
    
    const response = await openai.chat.completions.create({
      model: options.model || 'gpt-4',
      messages: messages,
      temperature: options.temperature || 0.7,
      max_tokens: options.max_tokens || 1500,
    });
    
    const duration = Date.now() - startTime;
    logger.info(`GPT-4 API ì‘ë‹µ ì™„ë£Œ: ${duration}ms, í† í°=${response.usage?.total_tokens || 'N/A'}`);
    
    return response.choices[0].message.content;
  } catch (error) {
    logger.error(`GPT-4 API ì˜¤ë¥˜: ${error.message}`);
    throw new Error(`GPT-4 í˜¸ì¶œ ì˜¤ë¥˜: ${error.message}`);
  }
}